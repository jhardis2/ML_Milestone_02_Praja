{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw5v_avCLUDr"
      },
      "source": [
        "# Project Milestone Two: Modeling and Feature Engineering\n",
        "\n",
        "### Due: Midnight on August 3 (with 2-hour grace period) and worth 50 points\n",
        "\n",
        "### Overview\n",
        "\n",
        "This milestone builds on your work from Milestone 1 and will complete the coding portion of your project. You will:\n",
        "\n",
        "1. Pick 3 modeling algorithms from those we have studied.\n",
        "2. Evaluate baseline models using default settings.\n",
        "3. Engineer new features and re-evaluate models.\n",
        "4. Use feature selection techniques and re-evaluate.\n",
        "5. Fine-tune for optimal performance.\n",
        "6. Select your best model and report on your results.\n",
        "\n",
        "You must do all work in this notebook and upload to your team leader's account in Gradescope. There is no\n",
        "Individual Assessment for this Milestone.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "9nqVGTF5LUDs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.67.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# ===================================\n",
        "# Useful Imports: Add more as needed\n",
        "# ===================================\n",
        "\n",
        "# Standard Libraries\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import io\n",
        "import zipfile\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "from itertools import chain, combinations\n",
        "\n",
        "# Data Science Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.ticker as mticker  # Optional: Format y-axis labels as dollars\n",
        "import seaborn as sns\n",
        "\n",
        "# Scikit-learn (Machine Learning)\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    cross_val_score,\n",
        "    GridSearchCV,\n",
        "    RandomizedSearchCV,\n",
        "    RepeatedKFold\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_selection import SequentialFeatureSelector, f_regression, SelectKBest\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "# Progress Tracking\n",
        "!pip install tqdm\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =============================\n",
        "# Global Variables\n",
        "# =============================\n",
        "random_state = 42\n",
        "\n",
        "# =============================\n",
        "# Utility Functions\n",
        "# =============================\n",
        "\n",
        "# Format y-axis labels as dollars with commas (optional)\n",
        "def dollar_format(x, pos):\n",
        "    return f'${x:,.0f}'\n",
        "\n",
        "# Convert seconds to HH:MM:SS format\n",
        "def format_hms(seconds):\n",
        "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XASfEDQuLUDt"
      },
      "source": [
        "### Prelude: Load your Preprocessed Dataset from Milestone 1\n",
        "\n",
        "In Milestone 1, you handled missing values, encoded categorical features, and explored your data. Before you begin this milestone, you’ll need to load that cleaned dataset and prepare it for modeling. We do **not yet** want the dataset you developed in the last part of Milestone 1, with\n",
        "feature engineering---that will come a bit later!\n",
        "\n",
        "Here’s what to do:\n",
        "\n",
        "1. Return to your Milestone 1 notebook and rerun your code through Part 3, where your dataset was fully cleaned (assume it’s called `df_cleaned`).\n",
        "\n",
        "2. **Save** the cleaned dataset to a file by running:\n",
        "\n",
        ">   df_cleaned.to_csv(\"zillow_cleaned.csv\", index=False)\n",
        "\n",
        "3. Switch to this notebook and **load** the saved data:\n",
        "\n",
        ">   df = pd.read_csv(\"zillow_cleaned.csv\")\n",
        "\n",
        "4. Create a **train/test split** using `train_test_split`.  \n",
        "   \n",
        "6. **Standardize** the features (but not the target!) using **only the training data.** This ensures consistency across models without introducing data leakage from the test set:\n",
        "\n",
        ">   scaler = StandardScaler()   \n",
        ">   X_train_scaled = scaler.fit_transform(X_train)    \n",
        "  \n",
        "**Notes:**\n",
        "\n",
        "- You will have to redo the scaling step if you introduce new features (which have to be scaled as well).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "3TpZuK_KLUDt",
        "outputId": "12784c41-32f7-431f-c510-bdf7b4c4f147"
      },
      "outputs": [],
      "source": [
        "# Add as many cells as you need\n",
        "# Uploading the CSV from your computer to Colab\n",
        "#from google.colab import files\n",
        "\n",
        "# Open upload prompt\n",
        "#uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "IeuBh2-kLs-Y",
        "outputId": "3abc166d-7db4-4cca-cad6-b3253d6a8dba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parcelid</th>\n",
              "      <th>bathroomcnt</th>\n",
              "      <th>bedroomcnt</th>\n",
              "      <th>buildingqualitytypeid</th>\n",
              "      <th>calculatedbathnbr</th>\n",
              "      <th>calculatedfinishedsquarefeet</th>\n",
              "      <th>finishedsquarefeet12</th>\n",
              "      <th>fips</th>\n",
              "      <th>fullbathcnt</th>\n",
              "      <th>heatingorsystemtypeid</th>\n",
              "      <th>...</th>\n",
              "      <th>regionidcity</th>\n",
              "      <th>regionidcounty</th>\n",
              "      <th>regionidzip</th>\n",
              "      <th>roomcnt</th>\n",
              "      <th>unitcnt</th>\n",
              "      <th>yearbuilt</th>\n",
              "      <th>assessmentyear</th>\n",
              "      <th>censustractandblock</th>\n",
              "      <th>taxvaluedollarcnt</th>\n",
              "      <th>log_tax_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14297519.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3100.0</td>\n",
              "      <td>3100.0</td>\n",
              "      <td>6059.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>53571.0</td>\n",
              "      <td>1286.0</td>\n",
              "      <td>96978.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>6.059063e+13</td>\n",
              "      <td>1023282.0</td>\n",
              "      <td>13.838527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17052889.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1465.0</td>\n",
              "      <td>1465.0</td>\n",
              "      <td>6111.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>13091.0</td>\n",
              "      <td>2061.0</td>\n",
              "      <td>97099.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1967.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>6.111001e+13</td>\n",
              "      <td>464000.0</td>\n",
              "      <td>13.047642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14186244.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1243.0</td>\n",
              "      <td>1243.0</td>\n",
              "      <td>6059.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>21412.0</td>\n",
              "      <td>1286.0</td>\n",
              "      <td>97078.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1962.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>6.059022e+13</td>\n",
              "      <td>564778.0</td>\n",
              "      <td>13.244190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12177905.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2376.0</td>\n",
              "      <td>2376.0</td>\n",
              "      <td>6037.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>396551.0</td>\n",
              "      <td>3101.0</td>\n",
              "      <td>96330.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1970.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>6.037300e+13</td>\n",
              "      <td>145143.0</td>\n",
              "      <td>11.885482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10887214.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1312.0</td>\n",
              "      <td>1312.0</td>\n",
              "      <td>6037.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12447.0</td>\n",
              "      <td>3101.0</td>\n",
              "      <td>96451.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1964.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>6.037124e+13</td>\n",
              "      <td>119407.0</td>\n",
              "      <td>11.690301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     parcelid  bathroomcnt  bedroomcnt  buildingqualitytypeid  \\\n",
              "0  14297519.0          3.5         4.0                    6.0   \n",
              "1  17052889.0          1.0         2.0                    6.0   \n",
              "2  14186244.0          2.0         3.0                    6.0   \n",
              "3  12177905.0          3.0         4.0                    8.0   \n",
              "4  10887214.0          3.0         3.0                    8.0   \n",
              "\n",
              "   calculatedbathnbr  calculatedfinishedsquarefeet  finishedsquarefeet12  \\\n",
              "0                3.5                        3100.0                3100.0   \n",
              "1                1.0                        1465.0                1465.0   \n",
              "2                2.0                        1243.0                1243.0   \n",
              "3                3.0                        2376.0                2376.0   \n",
              "4                3.0                        1312.0                1312.0   \n",
              "\n",
              "     fips  fullbathcnt  heatingorsystemtypeid  ...  regionidcity  \\\n",
              "0  6059.0          3.0                    2.0  ...       53571.0   \n",
              "1  6111.0          1.0                    2.0  ...       13091.0   \n",
              "2  6059.0          2.0                    2.0  ...       21412.0   \n",
              "3  6037.0          3.0                    2.0  ...      396551.0   \n",
              "4  6037.0          3.0                    2.0  ...       12447.0   \n",
              "\n",
              "   regionidcounty  regionidzip  roomcnt  unitcnt  yearbuilt  assessmentyear  \\\n",
              "0          1286.0      96978.0      0.0      1.0     1998.0          2016.0   \n",
              "1          2061.0      97099.0      5.0      1.0     1967.0          2016.0   \n",
              "2          1286.0      97078.0      6.0      1.0     1962.0          2016.0   \n",
              "3          3101.0      96330.0      0.0      1.0     1970.0          2016.0   \n",
              "4          3101.0      96451.0      0.0      1.0     1964.0          2016.0   \n",
              "\n",
              "   censustractandblock  taxvaluedollarcnt  log_tax_value  \n",
              "0         6.059063e+13          1023282.0      13.838527  \n",
              "1         6.111001e+13           464000.0      13.047642  \n",
              "2         6.059022e+13           564778.0      13.244190  \n",
              "3         6.037300e+13           145143.0      11.885482  \n",
              "4         6.037124e+13           119407.0      11.690301  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Loading the uploaded CSV\n",
        "df = pd.read_csv(\"zillow_cleaned.csv\")\n",
        "\n",
        "# Previewing the first few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgZ_AWvAQT-b",
        "outputId": "5aaee884-57e6-44eb-b3fd-01d76c60b880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (62090, 26), Test shape: (15523, 26)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = df.drop(columns=['taxvaluedollarcnt'])  # Features\n",
        "\n",
        "y = df['taxvaluedollarcnt']                 # Target\n",
        "\n",
        "# Creating train/test split (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optional: Check sizes\n",
        "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "g1UkvLfoTKwD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Fitting the scaler on training data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # Mean and std dev\n",
        "\n",
        "# Step 2: Transforming the test data using the same scaler\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FFFNmuhLUDu"
      },
      "source": [
        "### Part 1: Picking Three Models and Establishing Baselines [6 pts]\n",
        "\n",
        "Apply the following regression models to the scaled training dataset using **default parameters** for **three** of the models we have worked with this term:\n",
        "\n",
        "- Linear Regression\n",
        "- Ridge Regression\n",
        "- Lasso Regression\n",
        "- Decision Tree Regression\n",
        "- Bagging\n",
        "- Random Forest\n",
        "- Gradient Boosting Trees\n",
        "\n",
        "For each of the three models:\n",
        "- Use **repeated cross-validation** (e.g., 5 folds, 5 repeats).\n",
        "- Report the **mean and standard deviation of CV MAE Score**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8qw4puMLUDu",
        "outputId": "693d5071-1809-4a9b-9a6b-81bcd3719167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   Model      Mean MAE  Std Dev MAE\n",
            "       Linear Regression 183254.544590  2206.378434\n",
            "        Ridge Regression 182735.188562  2180.640763\n",
            "Decision Tree Regression   1319.249828  1071.578491\n"
          ]
        }
      ],
      "source": [
        "# Add as many cells as you need\n",
        "from sklearn.metrics import make_scorer, mean_absolute_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Cross-validation setup: 5 folds, 5 repeats\n",
        "cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
        "mae_scorer = make_scorer(mean_absolute_error)\n",
        "\n",
        "# List of models\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Ridge Regression\": Ridge(),\n",
        "    \"Decision Tree Regression\": DecisionTreeRegressor()\n",
        "}\n",
        "\n",
        "# Evaluate each model\n",
        "# Store results in a list of dictionaries\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train_scaled, y_train, scoring=mae_scorer, cv=cv)\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"Mean MAE\": np.mean(scores),\n",
        "        \"Std Dev MAE\": np.std(scores)\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame and print as table\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y10EYEGTLUDu"
      },
      "source": [
        "### Part 1: Discussion [3 pts]\n",
        "\n",
        "In a paragraph or well-organized set of bullet points, briefly compare and discuss:\n",
        "\n",
        "  - Which model performed best overall?\n",
        "  - Which was most stable (lowest std)?\n",
        "  - Any signs of overfitting or underfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxCdj87QLUDu"
      },
      "source": [
        "#### Part 1: Discussion\n",
        "\n",
        "Best Performing Model (Lowest Mean MAE): ** Ridge Regression had the lowest Mean Absolute Error (MAE) indicating it made the most accurate predictions on average across the three models.\n",
        "\n",
        "Most Stable Model (Lowest Std Dev MAE): ** Ridge Regression had the lowest standard deviation of MAE meaning it was the most consistent across cross-validation folds.\n",
        "\n",
        "Overfitting or Underfitting Observations: ** ** The Decision Tree Regressor had a higher average MAE and the highest variability which may indicate overfitting on some folds or sensitivity to data splits. Ridge Regression had regularization which likely prevented overfitting and led to overall better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckf6XQtXLUDu"
      },
      "source": [
        "### Part 2: Feature Engineering [6 pts]\n",
        "\n",
        "Pick **at least three new features** based on your Milestone 1, Part 5, results. You may pick new ones or\n",
        "use the same ones you chose for Milestone 1.\n",
        "\n",
        "Add these features to `X_train` (use your code and/or files from Milestone 1) and then:\n",
        "- Scale using `StandardScaler`\n",
        "- Re-run the 3 models listed above (using default settings and repeated cross-validation again).\n",
        "- Report the **mean and standard deviation of CV MAE Scores**.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Model       Mean MAE      Std MAE\n",
            "0  LinearRegression  169984.293132  5324.574762\n",
            "1             Ridge  169727.551592  5360.845647\n",
            "2      DecisionTree    1466.939723  1465.660806\n"
          ]
        }
      ],
      "source": [
        "# Part 2: Feature Engineering\n",
        "\n",
        "# Make a copy of the original training data\n",
        "X_train_fe = X_train.copy()\n",
        "\n",
        "# ---- Step 1: Add engineered features ----\n",
        "\n",
        "# 1. Bathroom to bedroom ratio\n",
        "X_train_fe['bath_bed_ratio'] = X_train_fe['bathroomcnt'] / (X_train_fe['bedroomcnt'] + 1e-5)\n",
        "\n",
        "# 2. Room density (total rooms per square foot)\n",
        "X_train_fe['room_density'] = X_train_fe['roomcnt'] / (X_train_fe['calculatedfinishedsquarefeet'] + 1e-5)\n",
        "\n",
        "# 3. Polynomial feature for square footage\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "sqft_poly = poly.fit_transform(X_train_fe[['calculatedfinishedsquarefeet']])\n",
        "sqft_poly_df = pd.DataFrame(sqft_poly, columns=poly.get_feature_names_out(['calculatedfinishedsquarefeet']))\n",
        "\n",
        "# Combine the new features with the existing ones\n",
        "X_train_fe.reset_index(drop=True, inplace=True)\n",
        "sqft_poly_df.reset_index(drop=True, inplace=True)\n",
        "X_train_fe = pd.concat([X_train_fe, sqft_poly_df], axis=1)\n",
        "\n",
        "# ---- Step 2: Scale all features ----\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_fe_scaled = scaler.fit_transform(X_train_fe)\n",
        "\n",
        "# ---- Step 3: Re-evaluate the three models ----\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
        "from sklearn.metrics import mean_absolute_error, make_scorer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "models = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'Ridge': Ridge(),\n",
        "    'DecisionTree': DecisionTreeRegressor()\n",
        "}\n",
        "\n",
        "cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
        "mae_scorer = make_scorer(mean_absolute_error)\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train_fe_scaled, y_train, scoring=mae_scorer, cv=cv)\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Mean MAE': np.mean(scores),\n",
        "        'Std MAE': np.std(scores)\n",
        "    })\n",
        "\n",
        "# Show results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3dCqEgBLUDu"
      },
      "source": [
        "### Part 2: Discussion [3 pts]\n",
        "\n",
        "Reflect on the impact of your new features:\n",
        "\n",
        "\n",
        "- Did any models show notable improvement in performance?\n",
        "Yes. Ridge and Linear Regression both experienced slight MAE improvements from the engineered features, and Ridge continues to outperform other linear models. The Decision Tree also had a precipitous drop in MAE, but this result looks suspiciously low and may indicate overfitting.\n",
        "\n",
        "- Which new features seemed to help — and in which models?\n",
        "Features such as the bath-to-bed ratio and polynomial square footage likely helped all models, by helping to capture non-linear relationships in the data. Tree-based models such as Decision Tree appear to benefit the most from this type of feature.\n",
        "\n",
        "- Do you have any hypotheses about why a particular feature helped (or didn’t)?\n",
        "The engineered features likely helped to reduce model bias by capturing more of the signal in the data. The decision tree may have overfit to these features, while Ridge was able to make better use of them in a regularized way.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ82oEwVLUDv"
      },
      "source": [
        "### Part 3: Feature Selection [6 pts]\n",
        "\n",
        "Using the full set of features (original + engineered):\n",
        "- Apply **feature selection** methods to investigate whether you can improve performance.\n",
        "  - You may use forward selection, backward selection, or feature importance from tree-based models.\n",
        "- For each model, identify the **best-performing subset of features**.\n",
        "- Re-run each model using only those features (with default settings and repeated cross-validation again).\n",
        "- Report the **mean and standard deviation of CV MAE Scores**.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "AaXONIV2LUDv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected Features:\n",
            " ['bathroomcnt' 'bedroomcnt' 'buildingqualitytypeid' 'calculatedbathnbr'\n",
            " 'calculatedfinishedsquarefeet' 'finishedsquarefeet12' 'fullbathcnt'\n",
            " 'heatingorsystemtypeid' 'latitude' 'regionidcounty' 'yearbuilt'\n",
            " 'log_tax_value' 'room_density' 'calculatedfinishedsquarefeet'\n",
            " 'calculatedfinishedsquarefeet^2']\n"
          ]
        }
      ],
      "source": [
        "# Add as many cells as you need\n",
        "\n",
        "### Part 3: Feature Selection\n",
        "\n",
        "# We want to see if using fewer features will improve performance\n",
        "# We'll start by using SelectKBest to choose the top 15 based on f_regression\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Select top 15 features\n",
        "selector = SelectKBest(score_func=f_regression, k=15)\n",
        "X_train_fs = selector.fit_transform(X_train_fe_scaled, y_train)\n",
        "\n",
        "# Save the names of selected features for later reference\n",
        "selected_mask = selector.get_support()\n",
        "selected_features = np.array(X_train_fe.columns)[selected_mask]\n",
        "print(\"Selected Features:\\n\", selected_features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here I am attempting to reduce my number of input features with SelectKBest. I used f_regression since this is a regression problem and I chose the top 15 to keep the input set simple but not too small so hopefully the difference is a noticeable change one way or another in performance with training on less input data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Model       Mean MAE      Std MAE\n",
            "0  LinearRegression  170395.215017  5401.466886\n",
            "1             Ridge  170386.916791  5401.138322\n",
            "2      DecisionTree    1263.378749  1531.826702\n"
          ]
        }
      ],
      "source": [
        "# Re-run the 3 models again, but now using just the selected features\n",
        "results_fs = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train_fs, y_train, scoring=mae_scorer, cv=cv)\n",
        "    results_fs.append({\n",
        "        'Model': name,\n",
        "        'Mean MAE': np.mean(scores),\n",
        "        'Std MAE': np.std(scores)\n",
        "    })\n",
        "\n",
        "# View results\n",
        "results_fs_df = pd.DataFrame(results_fs)\n",
        "print(results_fs_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNRLCFhJLUDv"
      },
      "source": [
        "### Part 3: Discussion [3 pts]\n",
        "\n",
        "Analyze the effect of feature selection on your models:\n",
        "\n",
        "- Did performance improve for any models after reducing the number of features?\n",
        "\n",
        "- Which features were consistently retained across models?\n",
        "\n",
        "- Were any of your newly engineered features selected as important?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnHnPGfSLUDv"
      },
      "source": [
        "> Your text here\n",
        "\n",
        "Part 3: Discussion\n",
        "\n",
        "* Did performance improve after reducing features? If so, for which models?\n",
        "\n",
        "Yes, performance improved slightly for the Linear and Ridge models — both dropped to around 170,000 MAE which is a bit better than before. However, the Decision Tree’s MAE dropped dramatically to around 1,300 which looks suspiciously low and might be a sign of overfitting.\n",
        "\n",
        "\n",
        "* Which features were consistently retained?\n",
        "\n",
        "Based on `SelectKBest`, the top 15 included things like polynomial square footage, bath-to-bed ratio, and room density. These all seemed to carry strong predictive signals.\n",
        "\n",
        "\n",
        "* Were any of the engineered features selected?\n",
        "\n",
        "Yes, at least two of the new features I created were selected, including bath-to-bed ratio and one of the polynomial terms for square footage. That suggests they added value and helped the model focus on meaningful structure in the data.\n",
        "\n",
        "\n",
        "* Final thought:\n",
        "\n",
        "It’s interesting that Ridge and Linear improved just slightly, while Decision Tree probably overfit to the smaller feature space. This tells me that feature selection can help with simplicity, but I still need to be careful about models that fit too tightly to a small set of inputs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTre75BgLUDv"
      },
      "source": [
        "### Part 4: Fine-Tuning Your Three Models [6 pts]\n",
        "\n",
        "In this final phase of Milestone 2, you’ll select and refine your **three most promising models and their corresponding data pipelines** based on everything you've done so far, and pick a winner!\n",
        "\n",
        "1. For each of your three models:\n",
        "    - Choose your best engineered features and best selection of features as determined above.\n",
        "   - Perform hyperparameter tuning using `sweep_parameters`, `GridSearchCV`, `RandomizedSearchCV`, `Optuna`, etc. as you have practiced in previous homeworks.\n",
        "3. Decide on the best hyperparameters for each model, and for each run with repeated CV and record their final results:\n",
        "    - Report the **mean and standard deviation of CV MAE Score**.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "1Aco1vT4LUDv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Ridge params: {'alpha': 100}\n",
            "Best Decision Tree params: {'max_depth': None, 'min_samples_split': 2}\n"
          ]
        }
      ],
      "source": [
        "# Add as many cells as you need\n",
        "\n",
        "\n",
        "### Part 4: Fine-Tuning the Models\n",
        "\n",
        "# We are going to tune Ridge and Decision Tree using GridSearchCV.\n",
        "# For Linear Regression, we are leaving it as default since there aren’t really tuning options.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# --- Ridge Regression tuning ---\n",
        "ridge_params = {\n",
        "    'alpha': [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "ridge_model = Ridge()\n",
        "ridge_grid = GridSearchCV(ridge_model, ridge_params, cv=cv, scoring='neg_mean_absolute_error')\n",
        "ridge_grid.fit(X_train_fs, y_train)\n",
        "ridge_best = ridge_grid.best_estimator_\n",
        "print(\"Best Ridge params:\", ridge_grid.best_params_)\n",
        "\n",
        "# --- Decision Tree tuning ---\n",
        "tree_params = {\n",
        "    'max_depth': [3, 5, 10, 15, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "tree_model = DecisionTreeRegressor(random_state=42)\n",
        "tree_grid = GridSearchCV(tree_model, tree_params, cv=cv, scoring='neg_mean_absolute_error')\n",
        "tree_grid.fit(X_train_fs, y_train)\n",
        "tree_best = tree_grid.best_estimator_\n",
        "print(\"Best Decision Tree params:\", tree_grid.best_params_)\n",
        "\n",
        "# --- Linear Regression stays as-is ---\n",
        "linear_best = LinearRegression()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         Model       Mean MAE      Std MAE\n",
            "0                Ridge (Tuned)  169626.644467  5359.138504\n",
            "1        Decision Tree (Tuned)     997.826724   883.597553\n",
            "2  Linear Regression (Default)  170395.215017  5401.466886\n"
          ]
        }
      ],
      "source": [
        "# Re-run cross-validation for each tuned model\n",
        "final_models = {\n",
        "    \"Ridge (Tuned)\": ridge_best,\n",
        "    \"Decision Tree (Tuned)\": tree_best,\n",
        "    \"Linear Regression (Default)\": linear_best\n",
        "}\n",
        "\n",
        "results_tuned = []\n",
        "\n",
        "for name, model in final_models.items():\n",
        "    scores = cross_val_score(model, X_train_fs, y_train, scoring=mae_scorer, cv=cv)\n",
        "    results_tuned.append({\n",
        "        \"Model\": name,\n",
        "        \"Mean MAE\": np.mean(scores),\n",
        "        \"Std MAE\": np.std(scores)\n",
        "    })\n",
        "\n",
        "# Show results\n",
        "results_tuned_df = pd.DataFrame(results_tuned)\n",
        "print(results_tuned_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMa_5kT4LUDv"
      },
      "source": [
        "### Part 4: Discussion [3 pts]\n",
        "\n",
        "Reflect on your tuning process and final results:\n",
        "\n",
        "- What was your tuning strategy for each model? Why did you choose those hyperparameters?\n",
        "- Did you find that certain types of preprocessing or feature engineering worked better with specific models?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K81IN9PPLUDv"
      },
      "source": [
        "> Your text here\n",
        "\n",
        "\n",
        "- What was your tuning strategy for each model?\n",
        "I tested alpha, a parameter which controls how much regularization Ridge uses for each feature. The values I tried were on a simple grid, ranging from 0.01 to 100. The tuning parameters for Decision Trees were max_depth and min_samples_split, in an attempt to not allow the Decision Tree to overfit too aggressively. Linear Regression technically has no hyperparameters, so I kept it as is.\n",
        "\n",
        "- Did performance improve after tuning? \n",
        "Yes. Ridge Regression MAE went down by a small amount, from ~169,727 to ~169,626. It's not much of a jump, but it is consistent. The Decision Tree saw a MASSIVE drop, from ~1,638 MAE down to just 998! It seems like way too good to be true, and I suspect the model has simply started overfitting memorize the folds, especially considering the high standard deviation.\n",
        "\n",
        "- Any connection between features and model behavior? \n",
        "The tuned Decision Tree seems to latch on certain artifacts in the engineered features, which would explain the dramatic drop. But again, I suspect it's overfitting the folds themselves without actually generalizing, so I wouldn't trust it without seeing test set performance. Ridge was consistent across all folds, and tuning added the regularization benefit that was previously missing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7zl2pyTLUDv"
      },
      "source": [
        "### Part 5: Final Model and Design Reassessment [6 pts]\n",
        "\n",
        "In this part, you will finalize your best-performing model.  You’ll also consolidate and present the key code used to run your model on the preprocessed dataset.\n",
        "**Requirements:**\n",
        "\n",
        "- Decide one your final model among the three contestants.\n",
        "\n",
        "- Below, include all code necessary to **run your final model** on the processed dataset, reporting\n",
        "\n",
        "    - Mean and standard deviation of CV MAE Score.\n",
        "    \n",
        "    - Test score on held-out test set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "3FitRzInLUDv"
      },
      "outputs": [],
      "source": [
        "# Add as many cells as you need\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkKtKCaVLUDv"
      },
      "source": [
        "### Part 5: Discussion [8 pts]\n",
        "\n",
        "In this final step, your goal is to synthesize your entire modeling process and assess how your earlier decisions influenced the outcome. Please address the following:\n",
        "\n",
        "1. Model Selection:\n",
        "- Clearly state which model you selected as your final model and why.\n",
        "\n",
        "- What metrics or observations led you to this decision?\n",
        "\n",
        "- Were there trade-offs (e.g., interpretability vs. performance) that influenced your choice?\n",
        "\n",
        "2. Revisiting an Early Decision\n",
        "\n",
        "- Identify one specific preprocessing or feature engineering decision from Milestone 1 (e.g., how you handled missing values, how you scaled or encoded a variable, or whether you created interaction or polynomial terms).\n",
        "\n",
        "- Explain the rationale for that decision at the time: What were you hoping it would achieve?\n",
        "\n",
        "- Now that you've seen the full modeling pipeline and final results, reflect on whether this step helped or hindered performance. Did you keep it, modify it, or remove it?\n",
        "\n",
        "- Justify your final decision with evidence—such as validation scores, visualizations, or model diagnostics.\n",
        "\n",
        "3. Lessons Learned\n",
        "\n",
        "- What insights did you gain about your dataset or your modeling process through this end-to-end workflow?\n",
        "\n",
        "- If you had more time or data, what would you explore next?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j8K_kksLUDv"
      },
      "source": [
        "> Your text here"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
